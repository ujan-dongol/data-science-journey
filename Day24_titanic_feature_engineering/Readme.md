# Day 24 â€“ Titanic Data Preprocessing & Feature Engineering

##  Overview

This project focuses on preparing the Titanic dataset for machine learning by handling missing values and performing feature engineering.

Data preprocessing is a crucial stage before training ML models.

---

## Objectives
- Detect missing values
- Apply imputation techniques
- Remove irrelevant columns
- Engineer meaningful features
- Encode categorical variables
- Generate ML-ready dataset

---

## ðŸ›  Tools Used

- Python
- Pandas
- NumPy



---

## Techniques Applied

- Median Imputation (Age)
- Mode Imputation (Embarked)
- Column Removal (Deck)
- Feature Engineering (Family Size)
- Label Encoding (Sex)
- One-Hot Encoding (Embarked)

---

## Why This Matters

Proper preprocessing:

- Improves model accuracy
- Prevents training errors
- Reduces noise
- Enhances feature quality

---

## Interview Highlights

- Explain imputation strategies
- Justify median over mean
- Explain one-hot encoding
- Mention dummy variable trap
- Explain feature engineering importance

---

##  Conclusion

This project demonstrates practical preprocessing techniques 
essential for real-world machine learning workflows.